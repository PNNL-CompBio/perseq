{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly import offline\n",
    "from cufflinks import iplot\n",
    "from snakemake.utils import report\n",
    "\n",
    "PLOTLY_PARAMS = dict(\n",
    "    include_plotlyjs=False, show_link=False, output_type=\"div\", image_height=700\n",
    ")\n",
    "\n",
    "\n",
    "#parses log_file for extra info\n",
    "\n",
    "# def parse_log_file(log_file, keyword, expect_one_value=True):\n",
    "#     content = open(log_file).read()\n",
    "#     pos = content.find(keyword)\n",
    "#     if pos == -1:\n",
    "#         raise Exception(\"Didn't find {} in file:\\n\\n{}\".format(keyword, log_file))\n",
    "\n",
    "#     else:\n",
    "#         if expect_one_value:\n",
    "#             return content[pos:].split()[2]\n",
    "\n",
    "#         else:\n",
    "#             return content[pos:].split()[2:]\n",
    "\n",
    "#dependent functions for the others\n",
    "#function to parse kaiju output\n",
    "\n",
    "#parse the kaiju output\n",
    "def parse_align(alignment_file):\n",
    "    total_lines=0\n",
    "    order_dict={}\n",
    "    class_dict={}\n",
    "    phylum_dict={}\n",
    "    total_align=[]\n",
    "    #for alignment_file in file_list:\n",
    "    with open(alignment_file) as file:\n",
    "        classified=0\n",
    "        unc=0\n",
    "        for line in file:\n",
    "\n",
    "\n",
    "            total_lines+=1\n",
    "            toks=line.strip().split('\\t')\n",
    "            #print(toks)\n",
    "            classification=toks[0]\n",
    "\n",
    "            if classification =='C':\n",
    "                classified+=1\n",
    "                bits=toks[7].split(';')\n",
    "                order=bits[3].strip()\n",
    "                clas=bits[2]\n",
    "                phylum=bits[1]\n",
    "                if order in order_dict:\n",
    "                    order_dict[order]+=1\n",
    "                else:\n",
    "                    order_dict[order]=1\n",
    "                if clas in class_dict:\n",
    "                    class_dict[clas]+=1\n",
    "                else:\n",
    "                    class_dict[clas]=1\n",
    "                if phylum in phylum_dict:\n",
    "                    phylum_dict[phylum]+=1\n",
    "                else:\n",
    "                    phylum_dict[phylum]=1\n",
    "            else:\n",
    "                unc+=1\n",
    "    total=classified+unc\n",
    "             # or should this be a list. prob list\n",
    "            #print('family',family)\n",
    "    return order_dict,class_dict,phylum_dict,total \n",
    "\n",
    "\n",
    "#calculates the order for diversity \n",
    "def gini(x, corr=False):\n",
    "    \"\"\"Calculates Gini coefficient, the measure of inequality among values\n",
    "    of a frequency distribution. A Gini coefficient of zero expresses\n",
    "    perfect equality.\n",
    "\n",
    "    Port from ineq package in R::\n",
    "\n",
    "            > library(ineq)\n",
    "            > t <- c(1,2,6,7,8)\n",
    "            > Gini(t)\n",
    "            [1] 0.3166667\n",
    "            > Gini(t, corr=TRUE)\n",
    "            [1] 0.3958333\n",
    "\n",
    "    Args:\n",
    "        x (list): list or array of numbers\n",
    "        corr (Optional[bool]): finite sample correction\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "\n",
    "    >>> import numpy as np\n",
    "    >>> t = [1,2,6,7,8]\n",
    "    >>> gini(t) # doctest: +ELLIPSIS\n",
    "    0.3166...\n",
    "    >>> gini(t, corr=True) # doctest: +ELLIPSIS\n",
    "    0.3958...\n",
    "    >>> gini([]) # doctest: +ELLIPSIS\n",
    "    Traceback (most recent call last):\n",
    "     ...\n",
    "    AssertionError: x is empty\n",
    "    >>> t = [1,2,6,7,\"A\"]\n",
    "    >>> gini(t) # doctest: +ELLIPSIS\n",
    "    Traceback (most recent call last):\n",
    "     ...\n",
    "    ValueError: could not convert...\n",
    "    \"\"\"\n",
    "    x = np.array(x, dtype=float)\n",
    "    # filter out nan values as list is coming from merged dataframe\n",
    "    x = x[~np.isnan(x)]\n",
    "    n = len(x)\n",
    "    assert n > 0, \"x is empty\"\n",
    "    x.sort(kind=\"mergesort\")\n",
    "    G = sum(np.arange(1, n + 1) * x)\n",
    "    G = 2 * G / sum(x) - (n + 1)\n",
    "    if corr:\n",
    "        return G / (n - 1)\n",
    "    else:\n",
    "        return G / n\n",
    "    \n",
    "#step 2\n",
    "#so this will make the counts information that we need. but this should be put into a function because it needs to be done\n",
    "#for all three of the taxa\n",
    "import numpy as np\n",
    "def process_reads(tax_level, pandas_df):\n",
    "    '''This function will take the merged reads from the file and put them into a graphable\n",
    "    form for both counts and percents. It will return both. '''\n",
    "    #cols = [i for i in m.columns.tolist() if i.startswith(\"Percent_\")]\n",
    "    header=merged_phy_final.columns.tolist()\n",
    "    header.pop(0)\n",
    "    full= merged_phy_final.sort_values(by=header,ascending=False) #organize these by count\n",
    "\n",
    "    sample_order = []\n",
    "    for read_col in merged_phy_final.columns.tolist(): #this will make a list of the gini coefficient of where these should be located by diversity of the sample\n",
    "        if read_col.startswith(\"Reads_\"):\n",
    "            sample_order.append([read_col.strip(\"Reads_\"), gini(merged_phy_final[read_col])])\n",
    "    sample_order = sorted(sample_order, key=lambda x: x[1])\n",
    "\n",
    "    sub = full[[tax_level] + [\"Reads_%s\" % sample_order[i][0] for i in range(len(sample_order))]]\n",
    "    sub = sub.head(100)\n",
    "    cols=sub[tax_level].tolist()\n",
    "\n",
    "    #find the percent\n",
    "    sub_perc=sub[header].div(total_counts)\n",
    "    sub_perc_t=sub_perc.transpose()\n",
    "    sub_perc_t.columns=cols #reset the names \n",
    "\n",
    "\n",
    "    #these are just the counts\n",
    "    sub_t=sub.transpose() #needs to be in this form or it wont work\n",
    "    sub_t.columns = sub_t.loc[tax_level] #set the column names as the taxoomy levels \n",
    "    sub_t.drop([tax_level], inplace=True) #this just takes out the duplicate header\n",
    "    \n",
    "    return sub_t, sub_perc_t\n",
    "\n",
    "\n",
    "#step 1\n",
    "def df_by_merge(path,tax_level):\n",
    "    \"\"\"\n",
    "    Reads in multiple sample alignments from diamond in a given directory and merges them into\n",
    "    a single pandas.DataFrame. It returns a pandas dataframe for each of th\n",
    "    phylum that is ready to plug into the processing function. Also returns total counts\n",
    "    which is necessary to calculate the percentage of total that is being represented \n",
    "    \"\"\"\n",
    "    merged_phy = None\n",
    "    samples = []\n",
    "    total_counts=[]\n",
    "    for f in os.listdir(path):\n",
    "        f = os.path.join(path, f)\n",
    "\n",
    "        #print(f)\n",
    "        #if not f.endswith(\"%s_summary.txt\" % tax_level): continue\n",
    "        sample = os.path.basename(f).partition(\"_aln_names.txt\")[0]\n",
    "        samples.append(sample) #making a list of the sample headers\n",
    "        header = [tax_level,\"Reads_%s\" % sample]\n",
    "        if merged_phy is None:\n",
    "            #print('yes')\n",
    "            #merged = pd.read_table(f, header=0, names=header, comment=\"-\")\n",
    "            phy,ordr,clas,tc=parse_align(f)\n",
    "            #print(phy)\n",
    "            total_counts.append(tc)\n",
    "            merged_phy = pd.DataFrame(data=phy,index=[0]).transpose()\n",
    "            merged_phy.reset_index(inplace=True)\n",
    "            merged_phy.columns=header\n",
    "            merged_clas = pd.DataFrame(data=clas, index=[0]).transpose()\n",
    "            merged_clas.reset_index(inplace=True)\n",
    "            merged_clas.columns=header\n",
    "            merged_ord = pd.DataFrame(data=ordr, index=[0]).transpose()\n",
    "            merged_ord.reset_index(inplace=True)\n",
    "            merged_ord.columns=header\n",
    "            #cols = merged.columns.tolist() #make a list of the column headers from the merged file\n",
    "            #cols.remove(tax_level) #remove the order tag\n",
    "            #cols.insert(0, tax_level) #insert it at the front.\n",
    "            #merged = merged[cols]\n",
    "            continue\n",
    "        phy,ordr,clas,tc=parse_align(f)\n",
    "        total_counts.append(tc)\n",
    "        df1 = pd.DataFrame(data=phy,index=[0]).transpose()\n",
    "        df1.reset_index(inplace=True)\n",
    "        df1.columns=header\n",
    "        df2 = pd.DataFrame(data=ordr,index=[0]).transpose()\n",
    "        df2.reset_index(inplace=True)\n",
    "        df2.columns=header\n",
    "        df3 = pd.DataFrame(data=clas,index=[0]).transpose()\n",
    "        df3.reset_index(inplace=True)\n",
    "        df3.columns=header\n",
    "        merged_phy_final = merged_phy.merge(df1, on=tax_level, how=\"outer\")\n",
    "        merged_ord_final = merged_ord.merge(df2, on=tax_level, how=\"outer\")\n",
    "        merged_class_final = merged_clas.merge(df3, on=tax_level, how=\"outer\")\n",
    "        #print(total_counts)\n",
    "\n",
    "\n",
    "    p_done,p_perc_done=process_reads(tax_level,merged_phy_final)\n",
    "    c_done,c_perc_done=process_reads(tax_level,merged_class_final)\n",
    "    o_done,o_perc_done=process_reads(tax_level,merged_order_final)\n",
    "        \n",
    "    return p_done,p_perc_done,c_done, c_perc_done,o_done,o_perc_done\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_plots(p_done,c_done,o_done,y_axis_title):\n",
    "    ##code in this block works\n",
    "\n",
    "    # data traces are taxonomies across samples\n",
    "    data = [go.Bar(x=p_done.index, y=p_done[tax], name=tax, visible=True) for tax in p_done.columns.tolist()] + \\\n",
    "    [go.Bar(x=c_done.index, y=c_done[tax], name=tax, visible=False) for tax in c_done.columns.tolist()] + \\\n",
    "    [go.Bar(x=o_done.index, y=o_done[tax], name=tax, visible=True) for tax in o_done.columns.tolist()]\n",
    "\n",
    "\n",
    "    # the number of taxa\n",
    "    trace_length = len(o_done.columns)\n",
    "\n",
    "    # plot buttons\n",
    "    updatemenus = list([\n",
    "        dict(type=\"buttons\",\n",
    "             active=0,\n",
    "             buttons=list([   \n",
    "                dict(label = 'Phylum',\n",
    "                     method = 'update',\n",
    "                     args = [{'visible': [True]*trace_length + [False]*trace_length  + [False]*trace_length},\n",
    "                             {'yaxis': {\"title\": \"Percent\"}}\n",
    "                            ]),\n",
    "                dict(label = 'Class',\n",
    "                     method = 'update',\n",
    "                     args = [{'visible': [False]*trace_length + [True]*trace_length + [False]*trace_length},\n",
    "                             {'yaxis': {\"title\": \"Count\"}}\n",
    "                            ]),\n",
    "                dict(label = 'Order',\n",
    "                     method = 'update',\n",
    "                     args = [{'visible': [False]*trace_length + [False]*trace_length + [True]*trace_length},\n",
    "                             {'yaxis': {\"title\": \"Count\"}}\n",
    "                            ])\n",
    "            ]),\n",
    "             direction = 'left',\n",
    "             pad = {'r': 0, 't': 0},\n",
    "             showactive = True,\n",
    "             x = 0,\n",
    "             xanchor = 'left',\n",
    "             y = 1.2,\n",
    "             yanchor = 'top' \n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # initial layout\n",
    "    layout = dict(title=\"Assignments per Sample By Count (Top 20)\",\n",
    "                  updatemenus=updatemenus,\n",
    "                  barmode=\"stack\",\n",
    "                  margin={\"b\": 200},\n",
    "                  xaxis={\"tickangle\": -60},\n",
    "                  yaxis=y_axis_title,\n",
    "                  showlegend=False,\n",
    "                  hovermode='closest'\n",
    "                 )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "    return fig\n",
    "\n",
    "def main(path_to_files):\n",
    "    p_done,p_perc_done,c_done,c_perc_done,o_done,o_perc_done=df_by_merge(path_to_files)\n",
    "    div = {} #this this appears to be what the actual html is going to call on(because it contains the plot info)\n",
    "    labels = {\n",
    "        \"percentage\": \"Percent of Total Reads Aligned\",\n",
    "        \"counts\": \"Count of Alignments\",\n",
    "    }\n",
    "    for variable in [\n",
    "        \"percentage\", \"counts\"\n",
    "    ]:\n",
    "        if variable == 'counts'\n",
    "            y_axis_label = labels[variable]\n",
    "            div[variable] = offline.plot(iplot(\n",
    "                    make_plots(p_done,c_done,o_done,y_axis_label)\n",
    "                ),\n",
    "                **PLOTLY_PARAMS,\n",
    "            )\n",
    "        else:\n",
    "            y_axis_label = labels[variable]\n",
    "            div[variable] = offline.plot(iplot(\n",
    "                make_plots(p_perc_done,c_perc_done,o_perc_done,y_axis_label)\n",
    "                ),\n",
    "                **PLOTLY_PARAMS,\n",
    "        )\n",
    "            \n",
    "\n",
    "    report_str = \"\"\"\n",
    ".. raw:: html\n",
    "    <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "=============================================================\n",
    "ATLAS_ - Assembly Summary\n",
    "=============================================================\n",
    ".. _ATLAS: https://github.com/pnnl/atlas\n",
    ".. contents::\n",
    "    :backlinks: none\n",
    "Summary\n",
    "-------\n",
    "N50 Counts by Taxonomy\n",
    "***\n",
    ".. raw:: html\n",
    "    {div[counts]}\n",
    "Assembly Length Percentage by Taxonomy\n",
    "***************\n",
    ".. raw:: html\n",
    "    {div[percentage]}\n",
    "\n",
    "For more information see Table_1_\n",
    "Downloads\n",
    "---------\n",
    "\"\"\"\n",
    "    report(report_str, report_out, Table_1=combined_stats, stylesheet=os.path.join(os.path.abspath(os.path.dirname(__file__)), \"report.css\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--path_to_alignment_files\", nargs=\"+\")\n",
    "    p.add_argument(\"--report-out\")\n",
    "\n",
    "    args = p.parse_args()\n",
    "    main(\n",
    "        args.path_to_alignment_files,\n",
    "        args.report_out\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
