{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependent functions for the others\n",
    "#function to parse kaiju output\n",
    "\n",
    "#parse the kaiju output\n",
    "def parse_align(alignment_file):\n",
    "    total_lines=0\n",
    "    order_dict={}\n",
    "    class_dict={}\n",
    "    phylum_dict={}\n",
    "    total_align=[]\n",
    "    #for alignment_file in file_list:\n",
    "    with open(alignment_file) as file:\n",
    "        classified=0\n",
    "        unc=0\n",
    "        for line in file:\n",
    "\n",
    "\n",
    "            total_lines+=1\n",
    "            toks=line.strip().split('\\t')\n",
    "            #print(toks)\n",
    "            classification=toks[0]\n",
    "\n",
    "            if classification =='C':\n",
    "                classified+=1\n",
    "                bits=toks[7].split(';')\n",
    "                order=bits[3].strip()\n",
    "                clas=bits[2]\n",
    "                phylum=bits[1]\n",
    "                if order in order_dict:\n",
    "                    order_dict[order]+=1\n",
    "                else:\n",
    "                    order_dict[order]=1\n",
    "                if clas in class_dict:\n",
    "                    class_dict[clas]+=1\n",
    "                else:\n",
    "                    class_dict[clas]=1\n",
    "                if phylum in phylum_dict:\n",
    "                    phylum_dict[phylum]+=1\n",
    "                else:\n",
    "                    phylum_dict[phylum]=1\n",
    "            else:\n",
    "                unc+=1\n",
    "    total=classified+unc\n",
    "             # or should this be a list. prob list\n",
    "            #print('family',family)\n",
    "    return order_dict,class_dict,phylum_dict,total \n",
    "\n",
    "\n",
    "\n",
    "#will find the counts(pro)\n",
    "\n",
    "# def process_df(concat_df):\n",
    "#     '''This function will process the output so that it is in the proper form for plotting. this is total counts'''\n",
    "#     lol= concat_df.sort_values(by=[0,1],ascending=False)\n",
    "#     cols=['sampe 140','sample 164']\n",
    "#     lol.columns=cols\n",
    "#     top=lol.head(20) #grab top 20\n",
    "\n",
    "#     #top.rename(index=str, columns={\"0\": \"140\", \"1\": \"164\"})\n",
    "#     t_top=top.transpose() #must transpose for this method to work\n",
    "    \n",
    "    \n",
    "#     return t_top\n",
    "# def process_per(concat_df,d):\n",
    "#     '''This function will provide the percents of *total* read counts. Both aligned and unaligned'''\n",
    "#     full= concat_df.sort_values(by=[0,1],ascending=False)\n",
    "#     cols=['sampe 140','sample 164']\n",
    "#     full.columns=cols\n",
    "#     psorted=full.head(20) #grab top 20\n",
    "#     #sums=psorted.sum().tolist() #make list of the sums for each column\n",
    "#     perc=psorted.div(d) #divide by the sums to get the percents\n",
    "#     t_perc=perc.transpose()\n",
    "#     return t_perc\n",
    "\n",
    "#calculates the order for diversity \n",
    "def gini(x, corr=False):\n",
    "    \"\"\"Calculates Gini coefficient, the measure of inequality among values\n",
    "    of a frequency distribution. A Gini coefficient of zero expresses\n",
    "    perfect equality.\n",
    "\n",
    "    Port from ineq package in R::\n",
    "\n",
    "            > library(ineq)\n",
    "            > t <- c(1,2,6,7,8)\n",
    "            > Gini(t)\n",
    "            [1] 0.3166667\n",
    "            > Gini(t, corr=TRUE)\n",
    "            [1] 0.3958333\n",
    "\n",
    "    Args:\n",
    "        x (list): list or array of numbers\n",
    "        corr (Optional[bool]): finite sample correction\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "\n",
    "    >>> import numpy as np\n",
    "    >>> t = [1,2,6,7,8]\n",
    "    >>> gini(t) # doctest: +ELLIPSIS\n",
    "    0.3166...\n",
    "    >>> gini(t, corr=True) # doctest: +ELLIPSIS\n",
    "    0.3958...\n",
    "    >>> gini([]) # doctest: +ELLIPSIS\n",
    "    Traceback (most recent call last):\n",
    "     ...\n",
    "    AssertionError: x is empty\n",
    "    >>> t = [1,2,6,7,\"A\"]\n",
    "    >>> gini(t) # doctest: +ELLIPSIS\n",
    "    Traceback (most recent call last):\n",
    "     ...\n",
    "    ValueError: could not convert...\n",
    "    \"\"\"\n",
    "    x = np.array(x, dtype=float)\n",
    "    # filter out nan values as list is coming from merged dataframe\n",
    "    x = x[~np.isnan(x)]\n",
    "    n = len(x)\n",
    "    assert n > 0, \"x is empty\"\n",
    "    x.sort(kind=\"mergesort\")\n",
    "    G = sum(np.arange(1, n + 1) * x)\n",
    "    G = 2 * G / sum(x) - (n + 1)\n",
    "    if corr:\n",
    "        return G / (n - 1)\n",
    "    else:\n",
    "        return G / n\n",
    "#step 1\n",
    "def df_by_merge(path,tax_level):\n",
    "    \"\"\"\n",
    "    Reads in multiple sample alignments from diamond in a given directory and merges them into\n",
    "    a single pandas.DataFrame. It returns a pandas dataframe for each of th\n",
    "    phylum that is ready to plug into the processing function. Also returns total counts\n",
    "    which is necessary to calculate the percentage of total that is being represented \n",
    "    \"\"\"\n",
    "    merged_phy = None\n",
    "    samples = []\n",
    "    total_counts=[]\n",
    "    for f in os.listdir(path):\n",
    "        f = os.path.join(path, f)\n",
    "\n",
    "        #print(f)\n",
    "        #if not f.endswith(\"%s_summary.txt\" % tax_level): continue\n",
    "        sample = os.path.basename(f).partition(\"_aln_names.txt\")[0]\n",
    "        samples.append(sample) #making a list of the sample headers\n",
    "        header = [tax_level,\"Reads_%s\" % sample]\n",
    "        if merged_phy is None:\n",
    "            #print('yes')\n",
    "            #merged = pd.read_table(f, header=0, names=header, comment=\"-\")\n",
    "            phy,ordr,clas,tc=parse_align(f)\n",
    "            #print(phy)\n",
    "            total_counts.append(tc)\n",
    "            merged_phy = pd.DataFrame(data=phy,index=[0]).transpose()\n",
    "            merged_phy.reset_index(inplace=True)\n",
    "            merged_phy.columns=header\n",
    "            merged_clas = pd.DataFrame(data=clas, index=[0]).transpose()\n",
    "            merged_clas.reset_index(inplace=True)\n",
    "            merged_clas.columns=header\n",
    "            merged_ord = pd.DataFrame(data=ordr, index=[0]).transpose()\n",
    "            merged_ord.reset_index(inplace=True)\n",
    "            merged_ord.columns=header\n",
    "            #cols = merged.columns.tolist() #make a list of the column headers from the merged file\n",
    "            #cols.remove(tax_level) #remove the order tag\n",
    "            #cols.insert(0, tax_level) #insert it at the front.\n",
    "            #merged = merged[cols]\n",
    "            continue\n",
    "        phy,ordr,clas,tc=parse_align(f)\n",
    "        total_counts.append(tc)\n",
    "        df1 = pd.DataFrame(data=phy,index=[0]).transpose()\n",
    "        df1.reset_index(inplace=True)\n",
    "        df1.columns=header\n",
    "        df2 = pd.DataFrame(data=ordr,index=[0]).transpose()\n",
    "        df2.reset_index(inplace=True)\n",
    "        df2.columns=header\n",
    "        df3 = pd.DataFrame(data=clas,index=[0]).transpose()\n",
    "        df3.reset_index(inplace=True)\n",
    "        df3.columns=header\n",
    "        merged_phy_final = merged_phy.merge(df1, on=tax_level, how=\"outer\")\n",
    "        merged_ord_final = merged_ord.merge(df2, on=tax_level, how=\"outer\")\n",
    "        merged_class_final = merged_clas.merge(df3, on=tax_level, how=\"outer\")\n",
    "        print(total_counts)\n",
    "\n",
    "\n",
    "        \n",
    "    return merged_phy_final, merged_ord_final, merged_class_final, total_counts\n",
    "\n",
    "\n",
    "#step 2\n",
    "#so this will make the counts information that we need. but this should be put into a function because it needs to be done\n",
    "#for all three of the taxa\n",
    "import numpy as np\n",
    "def process_reads(tax_level, pandas_df):\n",
    "    '''This function will take the merged reads from the file and put them into a graphable\n",
    "    form for both counts and percents. It will return both. '''\n",
    "    #cols = [i for i in m.columns.tolist() if i.startswith(\"Percent_\")]\n",
    "    header=merged_phy_final.columns.tolist()\n",
    "    header.pop(0)\n",
    "    full= merged_phy_final.sort_values(by=header,ascending=False) #organize these by count\n",
    "\n",
    "    sample_order = []\n",
    "    for read_col in merged_phy_final.columns.tolist(): #this will make a list of the gini coefficient of where these should be located by diversity of the sample\n",
    "        if read_col.startswith(\"Reads_\"):\n",
    "            sample_order.append([read_col.strip(\"Reads_\"), gini(merged_phy_final[read_col])])\n",
    "    sample_order = sorted(sample_order, key=lambda x: x[1])\n",
    "\n",
    "    sub = full[[tax_level] + [\"Reads_%s\" % sample_order[i][0] for i in range(len(sample_order))]]\n",
    "    sub = sub.head(100)\n",
    "    cols=sub[tax_level].tolist()\n",
    "\n",
    "    #find the percent\n",
    "    sub_perc=sub[header].div(total_counts)\n",
    "    sub_perc_t=sub_perc.transpose()\n",
    "    sub_perc_t.columns=cols #reset the names \n",
    "\n",
    "\n",
    "    #these are just the counts\n",
    "    sub_t=sub.transpose() #needs to be in this form or it wont work\n",
    "    sub_t.columns = sub_t.loc[tax_level] #set the column names as the taxoomy levels \n",
    "    sub_t.drop([tax_level], inplace=True) #this just takes out the duplicate header\n",
    "\n",
    "    return sub_t, sub_perc_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 \n",
    "test_p,test_c,test_o,total_counts= df_by_merge(path,tax_level)\n",
    "#step 2\n",
    "p_done,p_perc_done=process_reads(tax_level,test_p)\n",
    "c_done,c_perc_done=process_reads(tax_level,test_c)\n",
    "o_done,o_perc_done=process_reads(tax_level,test_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##this will make counts graphs\n",
    "\n",
    "# data traces are taxonomies across samples\n",
    "data = [go.Bar(x=p_done.index, y=p_done[tax], name=tax, visible=True) for tax in p_done.columns.tolist()] + \\\n",
    "[go.Bar(x=c_done.index, y=c_done[tax], name=tax, visible=False) for tax in c_done.columns.tolist()] + \\\n",
    "[go.Bar(x=o_done.index, y=o_done[tax], name=tax, visible=True) for tax in o_done.columns.tolist()]\n",
    "\n",
    "\n",
    "# the number of taxa\n",
    "trace_length = len(o_done.columns)\n",
    "\n",
    "# plot buttons\n",
    "updatemenus = list([\n",
    "    dict(type=\"buttons\",\n",
    "         active=0,\n",
    "         buttons=list([   \n",
    "            dict(label = 'Phylum',\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': [True]*trace_length + [False]*trace_length  + [False]*trace_length},\n",
    "                         {'yaxis': {\"title\": \"Percent\"}}\n",
    "                        ]),\n",
    "            dict(label = 'Order',\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': [False]*trace_length + [True]*trace_length + [False]*trace_length},\n",
    "                         {'yaxis': {\"title\": \"Count\"}}\n",
    "                        ]),\n",
    "            dict(label = 'Class',\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': [False]*trace_length + [False]*trace_length + [True]*trace_length},\n",
    "                         {'yaxis': {\"title\": \"Count\"}}\n",
    "                        ])\n",
    "        ]),\n",
    "         direction = 'left',\n",
    "         pad = {'r': 0, 't': 0},\n",
    "         showactive = True,\n",
    "         x = 0,\n",
    "         xanchor = 'left',\n",
    "         y = 1.2,\n",
    "         yanchor = 'top' \n",
    "    )\n",
    "])\n",
    "\n",
    "# initial layout\n",
    "layout = dict(title=\"Assignments per Sample By Count (Top 20)\",\n",
    "              updatemenus=updatemenus,\n",
    "              barmode=\"stack\",\n",
    "              margin={\"b\": 200},\n",
    "              xaxis={\"tickangle\": -60},\n",
    "              yaxis={\"title\": \"Percent\"},\n",
    "              showlegend=False,\n",
    "              hovermode='closest'\n",
    "             )\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##this will make percents graph\n",
    "\n",
    "# data traces are taxonomies across samples\n",
    "data = [go.Bar(x=p_perc_done.index, y=p_perc_done[tax], name=tax, visible=True) for tax in p_perc_done.columns.tolist()] + \\\n",
    "[go.Bar(x=c_perc_done.index, y=c_perc_done[tax], name=tax, visible=False) for tax in c_perc_done.columns.tolist()] + \\\n",
    "[go.Bar(x=o_perc_done.index, y=o_perc_done[tax], name=tax, visible=True) for tax in o_perc_done.columns.tolist()]\n",
    "\n",
    "\n",
    "# the number of taxa\n",
    "trace_length = len(o_perc_done.columns)\n",
    "\n",
    "# plot buttons\n",
    "updatemenus = list([\n",
    "    dict(type=\"buttons\",\n",
    "         active=0,\n",
    "         buttons=list([   \n",
    "            dict(label = 'Phylum',\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': [True]*trace_length + [False]*trace_length  + [False]*trace_length},\n",
    "                         {'yaxis': {\"title\": \"Percent\"}}\n",
    "                        ]),\n",
    "            dict(label = 'Order',\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': [False]*trace_length + [True]*trace_length + [False]*trace_length},\n",
    "                         {'yaxis': {\"title\": \"Count\"}}\n",
    "                        ]),\n",
    "            dict(label = 'Class',\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': [False]*trace_length + [False]*trace_length + [True]*trace_length},\n",
    "                         {'yaxis': {\"title\": \"Count\"}}\n",
    "                        ])\n",
    "        ]),\n",
    "         direction = 'left',\n",
    "         pad = {'r': 0, 't': 0},\n",
    "         showactive = True,\n",
    "         x = 0,\n",
    "         xanchor = 'left',\n",
    "         y = 1.2,\n",
    "         yanchor = 'top' \n",
    "    )\n",
    "])\n",
    "\n",
    "# initial layout\n",
    "layout = dict(title=\"Assignments per Sample By Percentage of Total (Top 20)\",\n",
    "              updatemenus=updatemenus,\n",
    "              barmode=\"stack\",\n",
    "              margin={\"b\": 200},\n",
    "              xaxis={\"tickangle\": -60},\n",
    "              yaxis={\"title\": \"Percent\"},\n",
    "              showlegend=False,\n",
    "              hovermode='closest'\n",
    "             )\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
